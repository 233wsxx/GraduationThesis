% !Mode:: "TeX:UTF-8"

\chapter{池化}

池化 (Pooling) ，也称为子采样 (Subsampling) 或下采样 (Downsampling) ，是深度学习中常用的一种操作，尤其是在 CNN (Convolutional Neural Network, 卷积神经网络) 和处理序列数据的模型中。其主要目的包括降低维度、增强特征不变性以及增大感受野。

首先，池化层通过聚合输入特征图 (Feature Map) 或序列中的信息，显著减少后续层的参数数量和计算量，从而实现降低维度 (Dimensionality Reduction)。这有助于控制模型的复杂度并防止过拟合。其次，池化操作可以使模型对输入中的微小变化 (如平移、旋转) 更加鲁棒，实现特征不变性 (Feature Invariance)。例如，最大池化 (Max Pooling) 关注区域内最显著的特征，即使特征的位置发生轻微移动，池化后的输出也可能保持不变。最后，在 CNN 中，池化层可以有效地增大感受野 (Receptive Field)，使得网络能够捕捉到更大范围的上下文信息。

常见的池化操作类型包括最大池化、平均池化和全局池化。 最大池化 (Max Pooling) 在一个局部区域 (池化窗口) 内选择最大的特征值作为输出，倾向于保留最显著的特征。 平均池化 (Average Pooling) 计算一个局部区域内所有特征值的平均值作为输出，保留了区域内的整体信息。 全局池化 (Global Pooling) 将整个特征图或序列缩减为一个单一的值 (或一个固定大小的向量)。例如，GAP (Global Average Pooling, 全局平均池化) 计算整个特征图的平均值。全局池化常用于将卷积层的输出连接到全连接层，或者在处理序列数据时聚合整个序列的信息。

\section{模型中的池化应用：带掩码的平均池化}

在这个特定的模型中，输入是可变长度的 PMT 命中序列。经过特征嵌入和 GPT 编码器处理后，我们得到一个形状为 $(T \times d_{in})$ 的输出序列 $X_{enc}$，其中 $T$ 是序列长度 (可能包含填充) ，$d_{in}$ 是模型的内部嵌入维度。由于输入序列的长度 $T$ 是可变的，并且为了进行最终的顶点位置回归 (需要一个固定大小的输入) ，我们需要将这个可变长度的序列 $X_{enc}$ 聚合 (或“池化”) 成一个单一的、固定大小的向量。

该模型采用的是带掩码的平均池化 (Masked Average Pooling)。选择这种方法主要是因为它能够有效处理变长序列，将不同长度的序列映射到相同维度的输出。同时，由于目标是基于整个事件 (所有有效命中) 的信息来预测顶点，需要聚合全局信息，全局池化是实现这一目标的自然选择。此外，由于较短的序列会被填充 (padding) 到最大长度 `max\_seq\_len`，在聚合信息时必须忽略填充部分，掩码 (Mask) 机制正好用于识别并忽略这些填充位置。最后，选择平均池化是因为它考虑了所有有效命中的贡献，将它们的特征表示进行平均，得到一个能代表整个事件“平均”特征的向量。相比之下，最大池化可能只关注最“突出”的少数命中，而对于顶点重建任务，综合所有命中的信息通常更为合理。

\subsection{具体实现}

令 $X_{enc} = [x_1, x_2, \dots, x_T]^T \in \mathbb{R}^{T \times d_{in}}$ 为 GPT 编码器的输出序列，其中 $x_i \in \mathbb{R}^{d_{in}}$。
令 $M = [m_1, m_2, \dots, m_T]$ 为对应的二进制掩码，其中 $m_i=1$ 表示第 $i$ 个位置是有效命中，$m_i=0$ 表示该位置是填充。

带掩码的平均池化计算如下：

\[ \bar{x}_{pool} = \frac{\sum_{i=1}^{T} x_i \cdot m_i}{\sum_{i=1}^{T} m_i + \epsilon} \]

这个公式计算了所有有效命中 ($m_i=1$) 对应的输出向量 $x_i$ 的和，然后除以有效命中的数量 ($\sum_{i=1}^{T} m_i$) ，得到平均向量 $\bar{x}_{pool} \in \mathbb{R}^{d_{in}}$。$\epsilon$ 是一个小的常数以防止除零。

这个池化后的向量 $\bar{x}_{pool}$ 捕获了整个事件序列的全局信息，并具有固定的维度 $d_{in}$。它随后被送入层归一化 (Layer Normalization) 和最终的线性输出层，以预测事件的 (x, y, z) 坐标。

\chapter{层归一化}

LN (Layer Normalization, 层归一化) 是一种在深度学习中广泛使用的归一化技术，特别是在处理序列数据（如 RNN (Recurrent Neural Network, 循环神经网络) 和 Transformer）时表现出色。与 BN (Batch Normalization, 批量归一化) 不同，BN 是在批次维度上对特征进行归一化，而 LN 是在单个样本的特征维度上进行归一化。

\subsection{层归一化原理}

对于神经网络某一层的一个样本的输出（或隐藏状态）向量 $h \in \mathbb{R}^{d}$（其中 $d$ 是该层的神经元数量或特征维度），层归一化首先计算该向量内所有元素的均值 $\mu$ 和标准差 $\sigma$：

\[ \mu = \frac{1}{d} \sum_{i=1}^{d} h_i \]
\[ \sigma = \sqrt{\frac{1}{d} \sum_{i=1}^{d} (h_i - \mu)^2 + \epsilon} \]

其中 $h_i$ 是向量 $h$ 的第 $i$ 个元素，$\epsilon$ 是一个很小的常数以防止除零。

然后，使用计算出的均值和标准差对该样本的输出向量 $h$ 进行归一化：

\[ \hat{h}_i = \frac{h_i - \mu}{\sigma} \]

最后，为了保持模型的表达能力，LN 引入了两个可学习的参数：增益 (gain) $\gamma \in \mathbb{R}^{d}$ 和偏置 (bias) $\beta \in \mathbb{R}^{d}$（维度与 $h$ 相同）。最终的输出 $LN(h)$ 计算如下：

\[ LN(h)_i = \gamma_i \hat{h}_i + \beta_i \]

$\gamma$ 和 $\beta$ 在训练过程中与其他模型参数一起学习，允许网络自适应地缩放和平移归一化后的特征。

\subsection{层归一化的优势}

层归一化具有几个显著优势。首先，它的计算完全在单个样本内部进行，不依赖于批次中的其他样本，因此独立于批次大小 (Batch Size Independent)。这意味着 LN 在批次大小很小（甚至为 1）或变化时也能稳定工作，这对于 RNN 或处理变长序列的模型尤其有利。其次，对于变长的序列数据，不同时间步的统计特性可能不同，BN 在这种情况下可能效果不佳，而 LN 对每个时间步独立进行归一化，因此更适用于序列数据，具有更好的鲁棒性。最后，与 BN 类似，LN 有助于平滑损失曲面，稳定训练动态，从而稳定梯度并加速模型收敛。

\subsection{在模型中的应用}

根据前文池化章节的描述，在模型中，层归一化的应用紧随在带掩码的平均池化 (Masked Average Pooling) 步骤之后。具体流程是：带掩码的平均池化层输出了一个固定维度的向量 $\bar{x}_{pool} \in \mathbb{R}^{d_{in}}$，这个向量聚合了来自 GPT 编码器输出的整个事件序列的全局信息。然后，这个池化后的向量 $\bar{x}_{pool}$ 被直接送入一个层归一化层。LN 层会计算 $\bar{x}_{pool}$ 向量内部 $d_{in}$ 个特征元素的均值和标准差，并对其进行归一化和仿射变换（使用可学习的 $\gamma$ 和 $\beta$ 参数）。在将聚合后的特征向量 $\bar{x}_{pool}$ 输入到最终的线性输出层之前应用 LN，主要目的是稳定这一层输入的分布，减少内部协变量偏移 (Internal Covariate Shift)，有助于后续线性层更好地学习从全局特征到最终 (x, y, z) 坐标的映射，可能加速训练收敛并提高模型的泛化能力。最后，经过层归一化处理后的向量，再被送入最终的线性层进行坐标预测。

\chapter{源代码}

% 本章列出了用于模型训练、验证、测试以及与传统方法对比分析的核心 Python 脚本。

% \begin{lstlisting}[language=Python, caption={模型训练、验证与测试对比脚本 (train\_val\_test\_compare\_v1.py)}, label={lst:train_script}]
%     #!/usr/bin/env python
%     import os
%     import argparse
%     import numpy as np
%     from glob import glob
%     import uproot
%     import torch
%     import torch.nn as nn
%     import torch.nn.functional as F
%     from torch.utils.data import Dataset, DataLoader
%     import logging   # 用于写 training.log
%     import matplotlib
%     matplotlib.use('Agg')
%     import matplotlib.pyplot as plt
    
%      ########################
%     # 1. 参数解析
%      ########################
%     def get_args():
%         parser= argparse.ArgumentParser(description="Stream-based training + val + test + SF vs DL compare.")
%         parser.add_argument("--root_dir", type=str, required=True,
%                             help="包含所有 .root 文件的目录")
%         parser.add_argument("--tree_name", type=str, default="event_ntuple")
%         parser.add_argument("--pmt_position_file", type=str, required=True,
%                             help="PMT坐标文件，与训练脚本一致")
    
%         # 数据cut + mm->cm
%         parser.add_argument("--min_hits", type=int, default=1)
%         parser.add_argument("--max_hits", type=int, default=99999)
%         parser.add_argument("--min_energy", type=float, default=0.0)
%         parser.add_argument("--max_energy", type=float, default=99999.0)
%         parser.add_argument("--pos_cut", nargs=6, type=float, 
%                             default=[-9999,9999, -9999,9999, -9999,9999],
%                             help="[x_min x_max y_min y_max z_min z_max], mm")
%         parser.add_argument("--time_min", type=float, default=0.0)
%         parser.add_argument("--time_max", type=float, default=9999.0)
%         parser.add_argument("--max_seq_len", type=int, default=1000)
    
%         parser.add_argument("--hit_features", nargs="+", default=["time","x","y","z"])
%         parser.add_argument("--embed_dims", nargs="+", type=int, default=[8,8,8,8])
%         parser.add_argument("--sort_mode", type=str, choices=["time","pmt_id"], 
%                             default="time")
    
%         # 流式: chunk_size => 一次处理多少 root 文件, 避免OOM
%         parser.add_argument("--chunk_size", type=int, default=5,
%                             help="一次读取 chunk_size 个 root 文件 => parse events => random split train/val/test => train => accumulate test?")
    
%         # 事件级随机拆分比例 (train/val/test)
%         parser.add_argument("--train_ratio", type=float, default=0.7)
%         parser.add_argument("--val_ratio", type=float, default=0.2)
    
%         parser.add_argument("--train_epochs", type=int, default=10)
%         parser.add_argument("--batch_size", type=int, default=32)
%         parser.add_argument("--lr", type=float, default=1e-3)
%         parser.add_argument("--eta_min", type=float, default=1e-5)
%         parser.add_argument("--early_stop_patience", type=int, default=5)
    
%         parser.add_argument("--nhead", type=int, default=4)
%         parser.add_argument("--num_layers", type=int, default=4)
%         parser.add_argument("--dim_ff", type=int, default=256)
    
%         parser.add_argument("--num_gpus", type=int, default=1)
%         parser.add_argument("--save_model", type=str, default="best_model.pth")
%         parser.add_argument("--save_loss_fig", type=str, default="loss_curve.png")
%         parser.add_argument("--save_pred_fig_dir", type=str, default="pred_figs")
    
%         # WeightedMSELoss
%         parser.add_argument("--outlier_threshold", type=float, default=10.0)
%         parser.add_argument("--scale_outlier", type=float, default=2.0)
    
%         # 指定存放训练日志
%         parser.add_argument("--log_file", type=str, default="training.log",
%                             help="日志文件名，用于记录训练信息")
    
%         # 测试集最终对比时: 将新生成的 _DL.root 放在 out_root_dir
%         parser.add_argument("--out_root_dir", type=str, default="dl_root_files",
%                             help="用户指定的新 ROOT 文件输出目录")
    
%         return parser.parse_args()
    
%      ########################
%     # 2. 设置logging
%      ########################
%     def setup_logging(log_file):
%         logging.basicConfig(
%             filename= log_file,
%             filemode= "w",
%             level= logging.INFO,
%             format= "%(asctime)s - %(levelname)s - %(message)s"
%         )
%         # 同时在屏幕输出
%         console= logging.StreamHandler()
%         console.setLevel(logging.INFO)
%         formatter= logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
%         console.setFormatter(formatter)
%         logging.getLogger("").addHandler(console)
    
%      ########################
%     # 3. load_pmt_positions
%      ########################
%     def load_pmt_positions(pmt_file):
%         """
%         解析 pmt_position_file, 返回 pmt_dict={pid:(px,py,pz)}, pmt_id_max
%         """
%         pmt_dict= {}
%         pmt_id_max= 0
%         with open(pmt_file,"r") as pf:
%             for line in pf:
%                 arr= line.strip().split()
%                 if len(arr)<4:
%                     continue
%                 pid= int(arr[0])
%                 px,py,pz= map(float, arr[1:4])
%                 pmt_dict[pid]= (px,py,pz)
%                 if pid> pmt_id_max:
%                     pmt_id_max= pid
%         return pmt_dict, pmt_id_max
    
%      ########################
%     # 4. chunkify root file list
%      ########################
%     def chunkify_files(file_list, chunk_size):
%         for i in range(0, len(file_list), chunk_size):
%             yield file_list[i : i+chunk_size]
    
%      ########################
%     # 5. 读取 chunk files => parse events => shuffle => split => train/val/test
%      ########################
%     def load_chunk_events(file_chunk, tree_name, pmt_dict, args):
%         """
%         一次加载这 chunk_size 个 root 文件 => parse => cut => 事件列表.
%         返回 events = [ { 'time':..., 'pid':..., 'xx':..., 'yy':..., 'zz':..., 'target_cm':..., 'sf_x_mm':..., 'energy':..., ... }, ... ]
%         """
%         events= []
%         for rf in file_chunk:
%             data= uproot.concatenate(f"{rf}:{tree_name}", library="np")
%             N= len(data["gtid"])
%             for i in range(N):
%                 nh= data["nhits"][i]
%                 if not(args.min_hits<= nh <= args.max_hits):
%                     continue
%                 e_v= data["deposit_energy"][i]
%                 if not(args.min_energy<= e_v <= args.max_energy):
%                     continue
%                 x_mm= data["position_x"][i]
%                 y_mm= data["position_y"][i]
%                 z_mm= data["position_z"][i]
%                 if not(args.pos_cut[0]<= x_mm<=args.pos_cut[1] and
%                        args.pos_cut[2]<= y_mm<=args.pos_cut[3] and
%                        args.pos_cut[4]<= z_mm<=args.pos_cut[5]):
%                     continue
    
%                 # mm->cm
%                 x_cm= x_mm/10.0
%                 y_cm= y_mm/10.0
%                 z_cm= z_mm/10.0
    
%                 ht= data["hit_time_v"][i]
%                 pid= data["hit_PMT_id_v"][i]
%                 xx_arr= np.array([pmt_dict.get(pp,(0,0,0))[0] for pp in pid], dtype=np.float32)
%                 yy_arr= np.array([pmt_dict.get(pp,(0,0,0))[1] for pp in pid], dtype=np.float32)
%                 zz_arr= np.array([pmt_dict.get(pp,(0,0,0))[2] for pp in pid], dtype=np.float32)
    
%                 # time cut
%                 mask_= (ht>=args.time_min)&(ht<=args.time_max)
%                 ht= ht[mask_]
%                 pid= pid[mask_]
%                 xx_arr= xx_arr[mask_]
%                 yy_arr= yy_arr[mask_]
%                 zz_arr= zz_arr[mask_]
%                 if len(ht)<1:
%                     continue
    
%                 if args.sort_mode=="time":
%                     sidx= np.argsort(ht)
%                 else:
%                     sidx= np.argsort(pid)
%                 ht= ht[sidx]
%                 pid= pid[sidx]
%                 xx_arr= xx_arr[sidx]
%                 yy_arr= yy_arr[sidx]
%                 zz_arr= zz_arr[sidx]
%                 if len(ht)> args.max_seq_len:
%                     ht= ht[:args.max_seq_len]
%                     pid= pid[:args.max_seq_len]
%                     xx_arr= xx_arr[:args.max_seq_len]
%                     yy_arr= yy_arr[:args.max_seq_len]
%                     zz_arr= zz_arr[:args.max_seq_len]
    
%                 # SF
%                 if "sf_position_x" in data:
%                     sfx= data["sf_position_x"][i]
%                     sfy= data["sf_position_y"][i]
%                     sfz= data["sf_position_z"][i]
%                 else:
%                     sfx= sfy= sfz= 9999
    
%                 events.append({
%                     "time": ht,
%                     "pid": pid,
%                     "xx": xx_arr,
%                     "yy": yy_arr,
%                     "zz": zz_arr,
%                     "target_cm": np.array([x_cm,y_cm,z_cm], dtype=np.float32),
%                     "sf_x_mm": sfx,
%                     "sf_y_mm": sfy,
%                     "sf_z_mm": sfz,
%                     "energy": e_v,
%                     "nhits": nh
%                 })
%         return events
    
%      ########################
%     # 6. Dataset + DataLoader
%      ########################
%     class PositionDataset(Dataset):
%         def __init__(self, events):
%             self.events= events
%         def __len__(self):
%             return len(self.events)
%         def __getitem__(self, idx):
%             ev= self.events[idx]
%             # return hits + target
%             return (ev["time"], ev["pid"], ev["xx"], ev["yy"], ev["zz"], ev["target_cm"])
    
%     def collate_fn(batch):
%         all_t, all_pid, all_x, all_y, all_z, all_tgt, all_mk = [], [], [], [], [], [], []
%         max_len = 0
%         for (ht, pid, xx, yy, zz, tgt) in batch:
%             l = len(ht)
%             mk_ = np.zeros((l,), dtype=np.float32)
%             mk_[:l] = 1
%             if l > max_len:
%                 max_len = l
%             all_t.append(ht)
%             all_pid.append(pid)
%             all_x.append(xx)
%             all_y.append(yy)
%             all_z.append(zz)
%             all_tgt.append(tgt)
%             all_mk.append(mk_)
    
%         bt, bp, bx, by, bz, bmk = [], [], [], [], [], []
%         for i in range(len(all_t)):
%             sl = len(all_t[i])
%             t_ = np.zeros((max_len,), dtype=np.float32)
%             p_ = np.zeros((max_len,), dtype=np.int64)
%             x_ = np.zeros((max_len,), dtype=np.float32)
%             y_ = np.zeros((max_len,), dtype=np.float32)
%             z_ = np.zeros((max_len,), dtype=np.float32)
%             m_ = np.zeros((max_len,), dtype=np.float32)
    
%             t_[:sl] = all_t[i]
%             p_[:sl] = all_pid[i]
%             x_[:sl] = all_x[i]
%             y_[:sl] = all_y[i]
%             z_[:sl] = all_z[i]
%             m_[:sl] = all_mk[i]
    
%             bt.append(t_)
%             bp.append(p_)
%             bx.append(x_)
%             by.append(y_)
%             bz.append(z_)
%             bmk.append(m_)
    
%         # 一次性将列表转换为 NumPy 数组后，再创建 tensor
%         bt = torch.from_numpy(np.array(bt, dtype=np.float32))
%         bp = torch.from_numpy(np.array(bp, dtype=np.int64))
%         bx = torch.from_numpy(np.array(bx, dtype=np.float32))
%         by = torch.from_numpy(np.array(by, dtype=np.float32))
%         bz = torch.from_numpy(np.array(bz, dtype=np.float32))
%         bmk = torch.from_numpy(np.array(bmk, dtype=np.float32))
%         tg = torch.from_numpy(np.array(all_tgt, dtype=np.float32))
%         return (bt, bp, bx, by, bz, bmk, tg)
    
%      ########################
%     # 7. 网络定义
%      ########################
%     def init_weights_gpt(m):
%         if isinstance(m,nn.Linear):
%             nn.init.normal_(m.weight, mean=0.0, std=0.02)
%             if m.bias is not None:
%                 nn.init.zeros_(m.bias)
%         elif isinstance(m,nn.Embedding):
%             nn.init.normal_(m.weight, mean=0.0, std=0.02)
    
%     class FeatureEmbedding(nn.Module):
%         def __init__(self, max_pmt_id, feat_list, embed_dims_dict):
%             super().__init__()
%             self.feats= feat_list
%             self.embed_dict= nn.ModuleDict()
%             for f in self.feats:
%                 dim= embed_dims_dict[f]
%                 if f=="pmt_id":
%                     self.embed_dict[f]= nn.Embedding(max_pmt_id+1, dim)
%                 else:
%                     self.embed_dict[f]= nn.Linear(1, dim, bias=True)
    
%         def forward(self,t,pid,x,y,z):
%             outs=[]
%             if "time" in self.feats:
%                 outs.append(self.embed_dict["time"](t.unsqueeze(-1)))
%             if "pmt_id" in self.feats:
%                 outs.append(self.embed_dict["pmt_id"](pid))
%             if "x" in self.feats:
%                 outs.append(self.embed_dict["x"](x.unsqueeze(-1)))
%             if "y" in self.feats:
%                 outs.append(self.embed_dict["y"](y.unsqueeze(-1)))
%             if "z" in self.feats:
%                 outs.append(self.embed_dict["z"](z.unsqueeze(-1)))
%             return torch.cat(outs, dim=-1)
    
%     class SelfAttention(nn.Module):
%         def __init__(self, embed_dim, n_heads, dropout=0.1):
%             super().__init__()
%             self.embed_dim= embed_dim
%             self.n_heads= n_heads
%             self.head_dim= embed_dim//n_heads
%             self.c_attn= nn.Linear(embed_dim, 3*embed_dim)
%             self.c_proj= nn.Linear(embed_dim, embed_dim)
%             self.dropout= nn.Dropout(dropout)
%         def forward(self,x):
%             B,T,C= x.shape
%             qkv= self.c_attn(x)
%             q,k,v= qkv.split(C, dim=2)
%             q= q.reshape(B,T,self.n_heads,self.head_dim).transpose(1,2)
%             k= k.reshape(B,T,self.n_heads,self.head_dim).transpose(1,2)
%             v= v.reshape(B,T,self.n_heads,self.head_dim).transpose(1,2)
%             y= F.scaled_dot_product_attention(q,k,v, None, dropout_p=self.dropout.p)
%             y= y.transpose(1,2).reshape(B,T,C)
%             return self.c_proj(y)
    
%     class AttentionBlock(nn.Module):
%         def __init__(self, embed_dim, n_heads, dropout=0.1):
%             super().__init__()
%             self.ln1= nn.LayerNorm(embed_dim)
%             self.attn= SelfAttention(embed_dim,n_heads,dropout)
%             self.ln2= nn.LayerNorm(embed_dim)
%             self.mlp= nn.Sequential(
%                 nn.Linear(embed_dim,4*embed_dim),
%                 nn.GELU(),
%                 nn.Linear(4*embed_dim, embed_dim),
%                 nn.Dropout(dropout)
%             )
%         def forward(self,x):
%             x= x + self.attn(self.ln1(x))
%             x= x + self.mlp(self.ln2(x))
%             return x
    
%     class GPTEncoder(nn.Module):
%         def __init__(self, embed_dim, n_heads, num_layers, dropout=0.1):
%             super().__init__()
%             self.blocks= nn.ModuleList([
%                 AttentionBlock(embed_dim,n_heads,dropout) for _ in range(num_layers)
%             ])
%         def forward(self,x):
%             for blk in self.blocks:
%                 x= blk(x)
%             return x
    
%     class GPTRegressor(nn.Module):
%         def __init__(self,in_dim,n_heads,num_layers,out_dim=3,max_len=1000,dropout=0.1):
%             super().__init__()
%             self.inp_linear= nn.Linear(in_dim,in_dim)
%             self.pos_emb= nn.Embedding(max_len,in_dim)
%             self.encoder= GPTEncoder(in_dim,n_heads,num_layers,dropout)
%             self.ln_f= nn.LayerNorm(in_dim)
%             self.fc_out= nn.Linear(in_dim,out_dim)
%             self.apply(init_weights_gpt)
    
%         def forward(self, feats, mask):
%             B,T,C= feats.shape
%             x= self.inp_linear(feats)
%             idx= torch.arange(T, device=x.device).unsqueeze(0)
%             x= x + self.pos_emb(idx)
%             x= self.encoder(x)
%             m_= mask.unsqueeze(-1)
%             x_pooled= (x*m_).sum(dim=1)/(m_.sum(dim=1)+1e-12)
%             x_pooled= self.ln_f(x_pooled)
%             return self.fc_out(x_pooled)
    
%      ########################
%     # 8. WeightedMSELoss
%      ########################
%     class WeightedMSELoss(nn.Module):
%         def __init__(self, threshold=10.0, scale_outlier=2.0):
%             super().__init__()
%             self.threshold= threshold
%             self.scale_outlier= scale_outlier
%         def forward(self, pred, tgt):
%             # pred,tgt: (B,3), unit= cm
%             err= pred - tgt
%             dr= torch.sqrt((err**2).sum(dim=1)+1e-12)
%             mask_big= (dr> self.threshold)
%             dr2= dr**2
%             dr2[mask_big]= dr2[mask_big]*self.scale_outlier
%             return dr2.mean()
    
%      ########################
%     # 9. 训练辅助函数
%      ########################
%     def train_on_chunk(model, emb_module, event_subset, batch_size, criterion, optimizer, device):
%         """
%         对给定一批 'event_subset' 事件做一次 mini-batch 训练(只返回平均loss).
%         """
%         ds_chunk= PositionDataset(event_subset)
%         dl_chunk= DataLoader(ds_chunk, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)
%         model.train()
%         emb_module.train()
%         total_loss=0.0
%         total_samples=0
    
%         for batch in dl_chunk:
%             bt,bp,bx,by,bz,mk,tg= [x.to(device) for x in batch]
%             optimizer.zero_grad()
%             feats= emb_module(bt,bp,bx,by,bz)
%             out= model(feats,mk)
%             loss= criterion(out,tg)
%             loss.backward()
%             optimizer.step()
    
%             bs= bt.size(0)
%             total_loss+= loss.item()* bs
%             total_samples+= bs
    
%         if total_samples>0:
%             return total_loss/ total_samples
%         else:
%             return 9999.9
    
%      ########################
%     # 10. 主函数
%      ########################
%     def main():
%         args= get_args()
    
%         # 设置日志
%         if os.path.exists(args.log_file):
%             os.remove(args.log_file)
%         setup_logging(args.log_file)
%         logging.info("START SCRIPT with args=%s", str(args))
    
%         # 准备输出目录
%         os.makedirs(args.save_pred_fig_dir, exist_ok=True)
%         os.makedirs(args.out_root_dir, exist_ok=True)  # 用户指定存放 _DL.root 的目录
    
%         # 设备
%         if torch.cuda.is_available() and args.num_gpus>0:
%             device= torch.device("cuda:0")
%             logging.info(f"Using GPU: {device}")
%         else:
%             device= torch.device("cpu")
%             logging.info("Using CPU")
    
%         # 读 pmt
%         pmt_dict, pmt_id_max= load_pmt_positions(args.pmt_position_file)
    
%         # 收集root文件
%         file_list= sorted(glob(os.path.join(args.root_dir,"*.root")))
%         if not file_list:
%             logging.error("No .root in %s", args.root_dir)
%             return
    
%         # 构建模型
%         feat_dict={}
%         for f,d_ in zip(args.hit_features, args.embed_dims):
%             feat_dict[f]= d_
%         emb_in_dim= sum(args.embed_dims)
%         emb_module= FeatureEmbedding(pmt_id_max, args.hit_features, feat_dict).to(device)
%         model= GPTRegressor(
%             in_dim= emb_in_dim,
%             n_heads= args.nhead,
%             num_layers= args.num_layers,
%             out_dim= 3,
%             max_len= args.max_seq_len,
%             dropout= 0.1
%         ).to(device)
    
%         if device.type=="cuda" and args.num_gpus>1:
%             model= nn.DataParallel(model)
%             emb_module= nn.DataParallel(emb_module)
    
%         criterion= WeightedMSELoss(args.outlier_threshold, args.scale_outlier)
%         optimizer= torch.optim.Adam(list(model.parameters())+ list(emb_module.parameters()), lr=args.lr)
%         scheduler= torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.train_epochs, eta_min=args.eta_min)
    
%         # early stop
%         best_val_loss= float("inf")
%         wait_cnt= 0
%         train_losses= []
%         val_losses= []
    
%         # 准备用于 test compare
%         test_events_all= []  # 累加各chunk的 test events
    
%         # ============= 训练 EPOCH loop =============
%         for ep in range(args.train_epochs):
%             logging.info(f"=== EPOCH {ep+1}/{args.train_epochs} ===")
    
%             # chunkify files => for each chunk => load => split => train
%             chunk_files_list= list(chunkify_files(file_list, args.chunk_size))
%             chunk_sum_loss= 0.0
%             chunk_sum_count= 0
%             sum_val_loss= 0.0
%             sum_val_count= 0
    
%             for ic, chunk_fs in enumerate(chunk_files_list, start=1):
%                 events_chunk= load_chunk_events(chunk_fs, args.tree_name, pmt_dict, args)
%                 if not events_chunk:
%                     continue
%                 # shuffle chunk events
%                 np.random.shuffle(events_chunk)
%                 Nch= len(events_chunk)
%                 nch_train= int(Nch* args.train_ratio)
%                 nch_val= int(Nch* args.val_ratio)
%                 nch_test= Nch- nch_train- nch_val
    
%                 train_part= events_chunk[:nch_train]
%                 val_part= events_chunk[nch_train: nch_train+nch_val]
%                 test_part= events_chunk[nch_train+nch_val:]  # for final compare
    
%                 # 累加 test
%                 test_events_all.extend(test_part)
    
%                 # 训练 (train_part)
%                 if train_part:
%                     train_loss= train_on_chunk(model, emb_module, train_part, args.batch_size, criterion, optimizer, device)
%                     chunk_sum_loss+= train_loss* len(train_part)
%                     chunk_sum_count+= len(train_part)
%                     logging.info(f"[Epoch {ep+1}] chunk {ic}/{len(chunk_files_list)} train_loss={train_loss:.4f}, events={len(train_part)}")
    
%                 # 验证 (val_part)
%                 if val_part:
%                     ds_val= PositionDataset(val_part)
%                     dl_val= DataLoader(ds_val, batch_size=args.batch_size, shuffle=False, collate_fn=collate_fn)
%                     model.eval()
%                     emb_module.eval()
%                     val_loss= 0.0
%                     val_count=0
%                     with torch.no_grad():
%                         for batch in dl_val:
%                             bt,bp,bx,by,bz,mk,tg= [x.to(device) for x in batch]
%                             feats= emb_module(bt,bp,bx,by,bz)
%                             out= model(feats,mk)
%                             loss= criterion(out,tg)
%                             bs= bt.size(0)
%                             val_loss+= loss.item()* bs
%                             val_count+= bs
%                     if val_count>0:
%                         val_loss/= val_count
%                         sum_val_loss+= val_loss* val_count
%                         sum_val_count+= val_count
%                     logging.info(f"[Epoch {ep+1}] chunk {ic}/{len(chunk_files_list)} val_loss={val_loss:.4f}, events={val_count}")
    
%                 del events_chunk, train_part, val_part, test_part
%                 torch.cuda.empty_cache()
    
%             # end chunk loop for epoch
%             if chunk_sum_count>0:
%                 epoch_train_loss= chunk_sum_loss / chunk_sum_count
%             else:
%                 epoch_train_loss=9999.9
%             train_losses.append(epoch_train_loss)
    
%             if sum_val_count>0:
%                 epoch_val_loss= sum_val_loss / sum_val_count
%             else:
%                 epoch_val_loss=9999.9
%             val_losses.append(epoch_val_loss)
    
%             scheduler.step()
    
%             logging.info(f"=== EPOCH {ep+1} DONE: TrainLoss={epoch_train_loss:.4f}, ValLoss={epoch_val_loss:.4f}")
    
%             # early stop
%             if epoch_val_loss< best_val_loss:
%                 best_val_loss= epoch_val_loss
%                 torch.save(model.state_dict(), args.save_model)
%                 torch.save(emb_module.state_dict(), args.save_model+"_emb")
%                 logging.info("** [Info] Best model updated!")
%                 wait_cnt=0
%             else:
%                 wait_cnt+=1
%                 if wait_cnt>= args.early_stop_patience:
%                     logging.info("** [Info] Early stopping triggered!")
%                     break
    
%         # 画loss曲线
%         plt.figure()
%         plt.plot(range(1,len(train_losses)+1), train_losses, label="Train")
%         plt.plot(range(1,len(val_losses)+1), val_losses, label="Val")
%         plt.xlabel("Epoch")
%         plt.ylabel("WeightedMSELoss")
%         plt.legend()
%         plt.tight_layout()
%         loss_fig= os.path.join(args.save_pred_fig_dir, args.save_loss_fig)
%         plt.savefig(loss_fig)
%         plt.close()
%         logging.info(f"Training done. Loss curve => {loss_fig}")
    
%         # 加载 best
%         if isinstance(model, nn.DataParallel):
%             model.module.load_state_dict(torch.load(args.save_model, map_location=device))
%             emb_module.module.load_state_dict(torch.load(args.save_model+"_emb", map_location=device))
%         else:
%             model.load_state_dict(torch.load(args.save_model, map_location=device))
%             emb_module.load_state_dict(torch.load(args.save_model+"_emb", map_location=device))
    
%         model.eval()
%         emb_module.eval()
    
%         # ========== 最终 test 对比 SF vs DL => 画对比图 & 输出 root ==========
%         logging.info(f"Test events all = {len(test_events_all)}")
%         if not test_events_all:
%             logging.info("No test events collected, skip final compare.")
%             return
    
%         dl_x,dl_y,dl_z= [],[],[]
%         sf_x,sf_y,sf_z= [],[],[]
%         rx,ry,rz= [],[],[]
%         e_list= []
%         nh_list= []
    
%         with torch.no_grad():
%             for ev in test_events_all:
%                 ht= ev["time"]
%                 pid= ev["pid"]
%                 xx= ev["xx"]
%                 yy= ev["yy"]
%                 zz= ev["zz"]
%                 if len(ht)<1:
%                     dl_x.append(9999); dl_y.append(9999); dl_z.append(9999)
%                     sf_x.append(ev["sf_x_mm"]); sf_y.append(ev["sf_y_mm"]); sf_z.append(ev["sf_z_mm"])
%                     r_ = ev["target_cm"]*10.0
%                     rx.append(r_[0]); ry.append(r_[1]); rz.append(r_[2])
%                     e_list.append(ev["energy"])
%                     nh_list.append(ev["nhits"])
%                     continue
    
%                 mk= np.ones((len(ht)), dtype=np.float32)
%                 if len(ht)> args.max_seq_len:
%                     ht= ht[:args.max_seq_len]
%                     pid= pid[:args.max_seq_len]
%                     xx= xx[:args.max_seq_len]
%                     yy= yy[:args.max_seq_len]
%                     zz= zz[:args.max_seq_len]
%                     mk= mk[:args.max_seq_len]
    
%                 b_time= torch.tensor(ht, dtype=torch.float32).unsqueeze(0).to(device)
%                 b_pid= torch.tensor(pid, dtype=torch.long).unsqueeze(0).to(device)
%                 b_x= torch.tensor(xx, dtype=torch.float32).unsqueeze(0).to(device)
%                 b_y= torch.tensor(yy, dtype=torch.float32).unsqueeze(0).to(device)
%                 b_z= torch.tensor(zz, dtype=torch.float32).unsqueeze(0).to(device)
%                 b_m= torch.tensor(mk, dtype=torch.float32).unsqueeze(0).to(device)
%                 feats= emb_module(b_time,b_pid,b_x,b_y,b_z)
%                 out_cm= model(feats,b_m)  # (1,3)
%                 out_mm= out_cm[0].cpu().numpy()*10.0  # => mm
%                 dl_x.append(out_mm[0])
%                 dl_y.append(out_mm[1])
%                 dl_z.append(out_mm[2])
    
%                 sf_x.append(ev["sf_x_mm"])
%                 sf_y.append(ev["sf_y_mm"])
%                 sf_z.append(ev["sf_z_mm"])
    
%                 real_mm= ev["target_cm"]*10.0
%                 rx.append(real_mm[0]); ry.append(real_mm[1]); rz.append(real_mm[2])
    
%                 e_list.append(ev["energy"])
%                 nh_list.append(ev["nhits"])
    
%         dl_x= np.array(dl_x); dl_y= np.array(dl_y); dl_z= np.array(dl_z)
%         sf_x= np.array(sf_x); sf_y= np.array(sf_y); sf_z= np.array(sf_z)
%         rx= np.array(rx); ry= np.array(ry); rz= np.array(rz)
%         e_list= np.array(e_list)
%         nh_list= np.array(nh_list)
    
%         dl_dist= np.sqrt((dl_x - rx)**2 + (dl_y - ry)**2 + (dl_z - rz)**2)
%         sf_dist= np.sqrt((sf_x - rx)**2 + (sf_y - ry)**2 + (sf_z - rz)**2)
    
%         mean_dl= dl_dist.mean()
%         std_dl= dl_dist.std()
%         mean_sf= sf_dist.mean()
%         std_sf= sf_dist.std()
%         logging.info(f"Test Dist => DL mean={mean_dl:.2f}, std={std_dl:.2f}, SF mean={mean_sf:.2f}, std={std_sf:.2f}")
    
%         # compare_3Ddistance_SF_DL
%         plt.figure()
%         label_dl= f"DL: mean={mean_dl:.2f}, std={std_dl:.2f}"
%         label_sf= f"SF: mean={mean_sf:.2f}, std={std_sf:.2f}"
%         bins=50
%         plt.hist(dl_dist, bins=bins, alpha=0.5, edgecolor='black', color='red', label=label_dl)
%         plt.hist(sf_dist, bins=bins, alpha=0.5, edgecolor='black', color='blue', label=label_sf)
%         plt.xlabel("3D Distance (mm)")
%         plt.ylabel("Count")
%         plt.title("Test: SF vs DL 3D distance")
%         plt.legend()
%         plt.tight_layout()
%         compare_fig= os.path.join(args.save_pred_fig_dir, "compare_3Ddistance_SF_DL_v1.png")
%         plt.savefig(compare_fig)
%         plt.close()
%         logging.info(f"Saved => {compare_fig}")
    
%         # resolution vs energy
%         nbins=10
%         e_min,e_max= e_list.min(), e_list.max()
%         be= np.linspace(e_min,e_max,nbins+1)
%         bc= 0.5*(be[:-1]+ be[1:])
%         res_sf= []
%         res_dl= []
%         for i in range(nbins):
%             sel= (e_list>= be[i]) & (e_list< be[i+1])
%             if np.sum(sel)==0:
%                 res_sf.append(0)
%                 res_dl.append(0)
%             else:
%                 res_sf.append(sf_dist[sel].mean())
%                 res_dl.append(dl_dist[sel].mean())
    
%         plt.figure()
%         plt.plot(bc, res_sf, '-o', color='blue', label="SF")
%         plt.plot(bc, res_dl, '-o', color='red', label="DL")
%         plt.xlabel("Energy (MeV)")
%         plt.ylabel("Mean 3D distance (mm)")
%         plt.title("Resolution vs Energy (Test set)")
%         plt.legend()
%         plt.tight_layout()
%         fig_e= os.path.join(args.save_pred_fig_dir, "resolution_vs_energy_v1.png")
%         plt.savefig(fig_e)
%         plt.close()
%         logging.info(f"Saved => {fig_e}")
    
%         # resolution vs nhits
%         nbins2=10
%         nh_min, nh_max= nh_list.min(), nh_list.max()
%         bh= np.linspace(nh_min, nh_max, nbins2+1)
%         bc2= 0.5*(bh[:-1]+ bh[1:])
%         sf2, dl2= [], []
%         for i in range(nbins2):
%             sel= (nh_list>= bh[i]) & (nh_list< bh[i+1])
%             if np.sum(sel)==0:
%                 sf2.append(0)
%                 dl2.append(0)
%             else:
%                 sf2.append(sf_dist[sel].mean())
%                 dl2.append(dl_dist[sel].mean())
    
%         plt.figure()
%         plt.plot(bc2, sf2, '-o', color='blue', label="SF")
%         plt.plot(bc2, dl2, '-o', color='red', label="DL")
%         plt.xlabel("Nhit")
%         plt.ylabel("Mean 3D distance (mm)")
%         plt.title("Resolution vs Nhit (Test set)")
%         plt.legend()
%         plt.tight_layout()
%         fig_n= os.path.join(args.save_pred_fig_dir, "resolution_vs_nhits_v1.png")
%         plt.savefig(fig_n)
%         plt.close()
%         logging.info(f"Saved => {fig_n}")
    
%         # 写 test_set_DL.root
%         logging.info("Writing test set root with DL coords => out_root_dir")
    
%         dl_x= dl_x.astype(np.float32)
%         dl_y= dl_y.astype(np.float32)
%         dl_z= dl_z.astype(np.float32)
%         rx= rx.astype(np.float32)
%         ry= ry.astype(np.float32)
%         rz= rz.astype(np.float32)
%         outdict= {
%             "dl_position_x": dl_x,
%             "dl_position_y": dl_y,
%             "dl_position_z": dl_z,
%             "real_position_x": rx,
%             "real_position_y": ry,
%             "real_position_z": rz,
%             "sf_position_x": sf_x.astype(np.float32),
%             "sf_position_y": sf_y.astype(np.float32),
%             "sf_position_z": sf_z.astype(np.float32),
%             "energy": e_list.astype(np.float32),
%             "nhits": nh_list.astype(np.float32)
%         }
%         outroot= os.path.join(args.out_root_dir, "test_set_DL_v1.root")
%         with uproot.recreate(outroot) as fout:
%             fout[args.tree_name]= outdict
%         logging.info(f"Wrote => {outroot}")
    
%         logging.info("All done. Check logs in %s", args.log_file)
    
%     if __name__=="__main__":
%         main()
% \end{lstlisting}

